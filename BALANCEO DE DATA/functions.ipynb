{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"functions.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"b2R6RrPxf0Ph","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, confusion_matrix\n","\n","def eval_model(model, X_val, y_val):\n","  #Realizando la prediccion del modelo\n","  y_pred = model.predict(X_val)\n","  #Calculando el error cuadratico medio\n","  MSE =mean_squared_error(y_val, y_pred)\n","  #Generando la matriz de confusion\n","  conf = confusion_matrix(y_val, y_pred)\n","  #Calculando las metricas\n","  accuracy = accuracy_score(y_val, y_pred)\n","  precision = precision_score(y_val, y_pred)\n","  recall = recall_score(y_val, y_pred)\n","  f1score = f1_score(y_val, y_pred)\n","  \n","  #Print de las metricas\n","  print('El MSE para el modelo '+type(model).__name__ +' es: ',MSE)\n","  print('El accuracy para el modelo '+type(model).__name__ +' es: ',accuracy)\n","  print('El precision para el modelo '+type(model).__name__ +' es: ',precision)\n","  print('El recall para el modelo '+type(model).__name__ +' es: ',recall)\n","  print('El F1-score para el modelo '+type(model).__name__ +' es: ',f1score)\n","  \n","  sns.heatmap(conf,annot=True, fmt=\"d\", cmap=\"coolwarm\");\n","  return None"],"execution_count":0,"outputs":[]}]}